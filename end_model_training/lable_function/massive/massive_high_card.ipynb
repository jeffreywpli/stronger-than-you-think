{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2033/2033 [00:00<00:00, 6787.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with new weak labels has been saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from snorkel.labeling import LabelingFunction, PandasLFApplier\n",
    "ABSTAIN = -1\n",
    "import random\n",
    "\n",
    "# Original keywords\n",
    "keywords = {\n",
    "    \"alarm\": [\n",
    "        \"alarm\",\n",
    "        \"wake+up\"\n",
    "    ],\n",
    "    \"audio\": [\n",
    "        \" mute \",\n",
    "        \"volume\",\n",
    "        \" loud\",\n",
    "        \"quiet\"\n",
    "    ],\n",
    "    \"iot\": [\n",
    "        \"light\",\n",
    "        \"wemo\",\n",
    "        \"coffee\"\n",
    "    ],\n",
    "    \"calendar\": [\n",
    "        \"calendar\",\n",
    "        \"schedule\",\n",
    "        \"remind\"\n",
    "    ],\n",
    "    \"play\": [\n",
    "        \"play \",\n",
    "        \"podcast\",\n",
    "        \"audiobook\"\n",
    "    ],\n",
    "    \"general\": [\n",
    "        \"good morning\",\n",
    "        \"joke\",\n",
    "        \"explain\"\n",
    "    ],\n",
    "    \"datetime\": [\n",
    "        \"date+today\",\n",
    "        \"time+is\",\n",
    "        \"date+is\"\n",
    "    ],\n",
    "    \"takeaway\": [\n",
    "        \"takeaway\",\n",
    "        \"delivery\",\n",
    "        \"order\"\n",
    "    ],\n",
    "    \"news\": [\n",
    "        \"news\",\n",
    "        \"times\",\n",
    "        \"headline\"\n",
    "    ],\n",
    "    \"music\": [\n",
    "        \"what+song\",\n",
    "        \"save+song\",\n",
    "        \"shuffle\"\n",
    "    ],\n",
    "    \"weather\": [\n",
    "        \"weather\",\n",
    "        \"temperature\",\n",
    "        \" rain\",\n",
    "        \" snow\"\n",
    "    ],\n",
    "    \"qa\": [\n",
    "        \"stock\",\n",
    "        \"what's\",\n",
    "        \"define\",\n",
    "        \"describe\",\n",
    "        \"what is\",\n",
    "        \"what+mean\"\n",
    "    ],\n",
    "    \"social\": [\n",
    "        \"message\",\n",
    "        \"tweet\",\n",
    "        \"twitter\",\n",
    "        \"facebook\",\n",
    "        \"complain\",\n",
    "        \"status\"\n",
    "    ],\n",
    "    \"recommendation\": [\n",
    "        \"recommend\",\n",
    "        \"suggest\",\n",
    "        \"restaurant\",\n",
    "    ],\n",
    "    \"cooking\": [\n",
    "        \"recipe\",\n",
    "        \"timer\",\n",
    "        \"cook\"\n",
    "    ],\n",
    "    \"transport\": [\n",
    "        \"ticket\",\n",
    "        \"train\",\n",
    "        \"flight\",\n",
    "        \"accident\",\n",
    "        \"traffic\"\n",
    "    ],\n",
    "    \"email\": [\n",
    "        \"email\",\n",
    "        \"inbox\",\n",
    "        \"message+inbox\",\n",
    "        \"message+email\"\n",
    "    ],\n",
    "    \"lists\": [\n",
    "        \" list\",\n",
    "        \"create+list\",\n",
    "        \"delete+list\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Detailed labels mapping\n",
    "detailed_mapping = {\n",
    "    \"alarm\": [0, 14, 15],\n",
    "    \"audio\": [1, 23, 28, 26],\n",
    "    \"iot\": [2, 3, 4, 5, 6, 27, 29, 30, 19],\n",
    "    \"calendar\": [7, 38, 52],\n",
    "    \"play\": [8, 32, 39, 40, 47],\n",
    "    \"general\": [9, 10, 24],\n",
    "    \"datetime\": [11, 12],\n",
    "    \"takeaway\": [13, 20],\n",
    "    \"news\": [16],\n",
    "    \"music\": [17, 18, 22, 25],\n",
    "    \"weather\": [21],\n",
    "    \"qa\": [31, 36, 51, 58, 59],\n",
    "    \"social\": [33, 41],\n",
    "    \"recommendation\": [34, 37, 45],\n",
    "    \"cooking\": [35, 50],\n",
    "    \"transport\": [42, 44, 49, 57],\n",
    "    \"email\": [43, 48, 54, 56],\n",
    "    \"lists\": [46, 53, 55]\n",
    "}\n",
    "\n",
    "# Calculate the total number of weak labels needed\n",
    "number_of_weak_labels = len([kw for kws in keywords.values() for kw in kws])\n",
    "\n",
    "# Helper function for keyword LFs\n",
    "def keyword_LF(x, keyword=None, labels=None):\n",
    "    text = x['data']['text'].lower()\n",
    "    if \"+\" in keyword:\n",
    "        keywords_split = keyword.split(\"+\")\n",
    "        if all([k in text for k in keywords_split]):\n",
    "            return random.choice(labels)\n",
    "    else:\n",
    "        if keyword in text:\n",
    "            return random.choice(labels)\n",
    "    return ABSTAIN\n",
    "\n",
    "# Create labeling functions for each keyword\n",
    "def create_keyword_LFs(keywords, detailed_mapping):\n",
    "    lfs = []\n",
    "    for category, kw_list in keywords.items():\n",
    "        labels = detailed_mapping[category]\n",
    "        for keyword in kw_list:\n",
    "            lfs.append(LabelingFunction(name=f\"lf_{category}_{keyword}\", f=keyword_LF, resources={'keyword': keyword, 'labels': labels}))\n",
    "    return lfs\n",
    "\n",
    "# Create labeling functions\n",
    "lfs = create_keyword_LFs(keywords, detailed_mapping)\n",
    "\n",
    "# Load datasets\n",
    "dataset_name = \"massive\"\n",
    "idx_to_label = json.load(open(f\"../weak_datasets/{dataset_name}/label.json\"))\n",
    "label_to_idx = {l: i for i, l in idx_to_label.items()}\n",
    "\n",
    "test_data = json.load(open(f\"../weak_datasets/{dataset_name}/valid.json\", \"r\"))\n",
    "\n",
    "# Convert test data to DataFrame\n",
    "test_df = pd.DataFrame.from_dict(test_data, orient='index')\n",
    "\n",
    "# Applies a set of LFs (functions) to a dataset (in df form)\n",
    "def apply_LFs(lfs, dataset):\n",
    "    applier = PandasLFApplier(lfs=lfs)\n",
    "    L = applier.apply(df=dataset)\n",
    "    return L\n",
    "\n",
    "# Generate weak labels for the test dataset\n",
    "L_test = apply_LFs(lfs, test_df)\n",
    "\n",
    "# Convert the labeling matrix L_test to weak labels\n",
    "def convert_to_weak_labels(L, num_labels):\n",
    "    weak_labels = []\n",
    "    for row in L:\n",
    "        weak_label = [-1] * num_labels\n",
    "        for i, label in enumerate(row):\n",
    "            if label != ABSTAIN:\n",
    "                weak_label[i] = int(label)\n",
    "        weak_labels.append(weak_label)\n",
    "    return weak_labels\n",
    "\n",
    "test_df['weak_labels'] = convert_to_weak_labels(L_test, number_of_weak_labels)\n",
    "\n",
    "# Convert DataFrame back to dictionary format\n",
    "new_test_data = test_df.to_dict(orient='index')\n",
    "\n",
    "# Ensure all weak_labels are lists of integers\n",
    "for key in new_test_data:\n",
    "    new_test_data[key]['weak_labels'] = [int(i) for i in new_test_data[key]['weak_labels']]\n",
    "\n",
    "# Save the updated dataset\n",
    "dataset_name = 'massive_highcad'\n",
    "with open(f\"../weak_datasets/{dataset_name}/valid.json\", \"w\") as f:\n",
    "    json.dump(new_test_data, f, indent=2)\n",
    "\n",
    "print(\"Updated dataset with new weak labels has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Coverage: 0.6222331529758977\n",
      "acuracy for the not abstains\n",
      "0.33395348837209304\n",
      "acuracy for all\n",
      "0.17658632562715199\n"
     ]
    }
   ],
   "source": [
    "import label_improve as li\n",
    "\n",
    "test_df = li.massive_to_df(json.load(open(f\"../weak_datasets/{dataset_name}/valid.json\", \"r\")))\n",
    "\n",
    "li.analysis_LFs_with_weak_labels(test_df, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2033/2033 [00:00<00:00, 2064.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with new weak labels has been saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from snorkel.labeling import LabelingFunction, PandasLFApplier\n",
    "\n",
    "ABSTAIN = -1\n",
    "\n",
    "# Original keywords\n",
    "keywords = {\n",
    "    \"alarm\": [\n",
    "        \"alarm\",\n",
    "        \"wake+up\"\n",
    "    ],\n",
    "    \"audio\": [\n",
    "        \" mute \",\n",
    "        \"volume\",\n",
    "        \" loud\",\n",
    "        \"quiet\"\n",
    "    ],\n",
    "    \"iot\": [\n",
    "        \"light\",\n",
    "        \"wemo\",\n",
    "        \"coffee\"\n",
    "    ],\n",
    "    \"calendar\": [\n",
    "        \"calendar\",\n",
    "        \"schedule\",\n",
    "        \"remind\"\n",
    "    ],\n",
    "    \"play\": [\n",
    "        \"play \",\n",
    "        \"podcast\",\n",
    "        \"audiobook\"\n",
    "    ],\n",
    "    \"general\": [\n",
    "        \"good morning\",\n",
    "        \"joke\",\n",
    "        \"explain\"\n",
    "    ],\n",
    "    \"datetime\": [\n",
    "        \"date+today\",\n",
    "        \"time+is\",\n",
    "        \"date+is\"\n",
    "    ],\n",
    "    \"takeaway\": [\n",
    "        \"takeaway\",\n",
    "        \"delivery\",\n",
    "        \"order\"\n",
    "    ],\n",
    "    \"news\": [\n",
    "        \"news\",\n",
    "        \"times\",\n",
    "        \"headline\"\n",
    "    ],\n",
    "    \"music\": [\n",
    "        \"what+song\",\n",
    "        \"save+song\",\n",
    "        \"shuffle\"\n",
    "    ],\n",
    "    \"weather\": [\n",
    "        \"weather\",\n",
    "        \"temperature\",\n",
    "        \" rain\",\n",
    "        \" snow\"\n",
    "    ],\n",
    "    \"qa\": [\n",
    "        \"stock\",\n",
    "        \"what's\",\n",
    "        \"define\",\n",
    "        \"describe\",\n",
    "        \"what is\",\n",
    "        \"what+mean\"\n",
    "    ],\n",
    "    \"social\": [\n",
    "        \"message\",\n",
    "        \"tweet\",\n",
    "        \"twitter\",\n",
    "        \"facebook\",\n",
    "        \"complain\",\n",
    "        \"status\"\n",
    "    ],\n",
    "    \"recommendation\": [\n",
    "        \"recommend\",\n",
    "        \"suggest\",\n",
    "        \"restaurant\",\n",
    "    ],\n",
    "    \"cooking\": [\n",
    "        \"recipe\",\n",
    "        \"timer\",\n",
    "        \"cook\"\n",
    "    ],\n",
    "    \"transport\": [\n",
    "        \"ticket\",\n",
    "        \"train\",\n",
    "        \"flight\",\n",
    "        \"accident\",\n",
    "        \"traffic\"\n",
    "    ],\n",
    "    \"email\": [\n",
    "        \"email\",\n",
    "        \"inbox\",\n",
    "        \"message+inbox\",\n",
    "        \"message+email\"\n",
    "    ],\n",
    "    \"lists\": [\n",
    "        \" list\",\n",
    "        \"create+list\",\n",
    "        \"delete+list\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Detailed labels mapping\n",
    "detailed_mapping = {\n",
    "    \"alarm\": [0, 14, 15],\n",
    "    \"audio\": [1, 23, 28, 26],\n",
    "    \"iot\": [2, 3, 4, 5, 6, 27, 29, 30, 19],\n",
    "    \"calendar\": [7, 38, 52],\n",
    "    \"play\": [8, 32, 39, 40, 47],\n",
    "    \"general\": [9, 10, 24],\n",
    "    \"datetime\": [11, 12],\n",
    "    \"takeaway\": [13, 20],\n",
    "    \"news\": [16],\n",
    "    \"music\": [17, 18, 22, 25],\n",
    "    \"weather\": [21],\n",
    "    \"qa\": [31, 36, 51, 58, 59],\n",
    "    \"social\": [33, 41],\n",
    "    \"recommendation\": [34, 37, 45],\n",
    "    \"cooking\": [35, 50],\n",
    "    \"transport\": [42, 44, 49, 57],\n",
    "    \"email\": [43, 48, 54, 56],\n",
    "    \"lists\": [46, 53, 55]\n",
    "}\n",
    "\n",
    "# Calculate the total number of weak labels needed\n",
    "number_of_weak_labels = sum(len(detailed_mapping[category]) * len(keywords[category]) for category in keywords)\n",
    "\n",
    "# Helper function for converting an individual keyword into an LF\n",
    "def _keyword_LF(x, keyword=None, label=None):\n",
    "    text = x['data']['text'].lower()\n",
    "    if \"+\" in keyword:\n",
    "        keywords_split = keyword.split(\"+\")\n",
    "        return label if all([k in text for k in keywords_split]) else ABSTAIN\n",
    "    else:\n",
    "        return label if keyword in text else ABSTAIN\n",
    "\n",
    "# Allows us to convert from a keyword_dict {class: [keyword list]} to a set of LFs \n",
    "def keywords_to_LFs(keyword_dict, detailed_mapping):\n",
    "    lfs = []\n",
    "    for category, kw_list in keyword_dict.items():\n",
    "        detailed_labels = detailed_mapping[category]\n",
    "        for keyword in kw_list:\n",
    "            for label in detailed_labels:\n",
    "                lfs.append(LabelingFunction(name=f\"lf_{keyword}_{label}\", f=_keyword_LF, resources={'keyword': keyword, 'label': label}))\n",
    "    return lfs\n",
    "\n",
    "# Create labeling functions\n",
    "lfs = keywords_to_LFs(keywords, detailed_mapping)\n",
    "\n",
    "# Load datasets\n",
    "dataset_name = \"massive\"\n",
    "idx_to_label = json.load(open(f\"../weak_datasets/{dataset_name}/label.json\"))\n",
    "label_to_idx = {l: i for i, l in idx_to_label.items()}\n",
    "\n",
    "test_data = json.load(open(f\"../weak_datasets/{dataset_name}/valid.json\", \"r\"))\n",
    "\n",
    "# Convert test data to DataFrame\n",
    "test_df = pd.DataFrame.from_dict(test_data, orient='index')\n",
    "\n",
    "# Applies a set of LFs (functions) to a dataset (in df form)\n",
    "def apply_LFs(lfs, dataset):\n",
    "    applier = PandasLFApplier(lfs=lfs)\n",
    "    L = applier.apply(df=dataset)\n",
    "    return L\n",
    "\n",
    "# Generate weak labels for the test dataset\n",
    "L_test = apply_LFs(lfs, test_df)\n",
    "\n",
    "# Convert the labeling matrix L_test to weak labels\n",
    "def convert_to_weak_labels(L, num_labels):\n",
    "    weak_labels = []\n",
    "    for row in L:\n",
    "        weak_label = [-1] * num_labels\n",
    "        for i, label in enumerate(row):\n",
    "            if label != ABSTAIN:\n",
    "                weak_label[i] = int(label)\n",
    "        weak_labels.append(weak_label)\n",
    "    return weak_labels\n",
    "\n",
    "test_df['weak_labels'] = convert_to_weak_labels(L_test, number_of_weak_labels)\n",
    "\n",
    "# Convert DataFrame back to dictionary format\n",
    "new_test_data = test_df.to_dict(orient='index')\n",
    "\n",
    "# Ensure all weak_labels are lists of integers\n",
    "for key in new_test_data:\n",
    "    new_test_data[key]['weak_labels'] = [int(i) for i in new_test_data[key]['weak_labels']]\n",
    "dataset_name = 'massive_higcad2'\n",
    "# Save the updated dataset\n",
    "with open(f\"../weak_datasets/{dataset_name}/valid.json\", \"w\") as f:\n",
    "    json.dump(new_test_data, f, indent=2)\n",
    "\n",
    "print(\"Updated dataset with new weak labels has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoWS-Bench-101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
